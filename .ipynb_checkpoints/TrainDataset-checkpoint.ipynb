{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83a0cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "# Get current CPU usage as a percentage\n",
    "cpu_usage = psutil.cpu_percent()\n",
    "\n",
    "# Get current memory usage\n",
    "memory_usage = psutil.virtual_memory()\n",
    "\n",
    "# Convert memory usage object to a dictionary\n",
    "memory_usage_dict = dict(memory_usage._asdict())\n",
    "\n",
    "# Print results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3368e0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  2\n",
      "  2  2  2  2  2  3  3  3  3  3  3  3  4  4  4  4  4  4  5  5  5  5  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7\n",
      "  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "dir = \"dataset\"\n",
    "detector = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "directorynames = os.listdir(dir)  # directory names inside parent\n",
    "for directoryname in directorynames:\n",
    "    if directoryname.startswith(\"s\"):\n",
    "        x = directoryname.replace(\"s\", \"\")\n",
    "    label = int(x)\n",
    "    directorypath = dir + \"/\" + directoryname  # directory path\n",
    "\n",
    "    imagenames = os.listdir(directorypath)\n",
    "    for imagename in imagenames:\n",
    "        if not imagename.startswith(\".\"):\n",
    "            imagepath = directorypath + \"/\" + imagename  # image path\n",
    "\n",
    "            img = cv2.imread(imagepath)\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(src=img, dsize=(200, 200))\n",
    "            img = np.array(img)\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "data = data.reshape((-1, 200, 200, 1))\n",
    "print(labels)\n",
    "X_train = data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "47a54476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "afaff872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c7b396a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_240 (Conv2D)         (None, 200, 200, 64)      1664      \n",
      "                                                                 \n",
      " activation_424 (Activation)  (None, 200, 200, 64)     0         \n",
      "                                                                 \n",
      " max_pooling2d_236 (MaxPooli  (None, 66, 66, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 66, 66, 128)       73856     \n",
      "                                                                 \n",
      " activation_425 (Activation)  (None, 66, 66, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_237 (MaxPooli  (None, 22, 22, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_92 (Flatten)        (None, 61952)             0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 128)               7929984   \n",
      "                                                                 \n",
      " activation_426 (Activation)  (None, 128)              0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_427 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,006,794\n",
      "Trainable params: 8,006,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "start training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1622\n  y sizes: 507\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18808\\2600979919.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m# Model.fit(X_train, trainY, batch_size=5, epochs=20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Complete training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1846\u001b[0m             )\n\u001b[0;32m   1847\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1622\n  y sizes: 507\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "Model = Sequential()\n",
    "shape = (200, 200, 1)\n",
    "Model.add(Conv2D(64, (5, 5), padding=\"same\", input_shape=shape))\n",
    "Model.add(Activation(\"relu\"))\n",
    "Model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "Model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "Model.add(Activation(\"relu\"))\n",
    "Model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(128))\n",
    "Model.add(Activation(\"relu\"))\n",
    "Model.add(Dense(10))\n",
    "Model.add(Activation(\"softmax\"))\n",
    "\n",
    "Model.summary()\n",
    "Model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(\"start training\")\n",
    "Model.fit(X_train, trainY, batch_size=20, epochs=20,validation_split=0.2)\n",
    "# Model.fit(X_train, trainY, batch_size=5, epochs=20)\n",
    "print(\"Complete training\")\n",
    "Model.save(\"khuonmat.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533838a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155651b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
